#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„ EdgeAI æ•°æ®åº“ç®¡ç†æ–‡ä»¶
æ•´åˆæ‰€æœ‰æ•°æ®åº“ç›¸å…³åŠŸèƒ½ï¼šåˆå§‹åŒ–ã€æ•°æ®åˆ›å»ºã€æµ‹è¯•ã€è¿ç§»ç­‰
"""

import sys
import os
import json
import random
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
root_dir = Path(__file__).parent.parent.parent
sys.path.append(str(root_dir))

from sqlalchemy.exc import IntegrityError
from passlib.context import CryptContext
from database import engine, SessionLocal, create_tables, drop_tables, get_db
from models import User, Project, Model, Node, NodeConnection, NodeMetric

# å¯†ç å“ˆå¸Œ
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

class EdgeAIDatabaseManager:
    """EdgeAI æ•°æ®åº“ç»Ÿä¸€ç®¡ç†å™¨"""
    
    def __init__(self):
        self.db = None
    
    def get_session(self):
        """è·å–æ•°æ®åº“ä¼šè¯"""
        if self.db is None:
            self.db = SessionLocal()
        return self.db
    
    def close_session(self):
        """å…³é—­æ•°æ®åº“ä¼šè¯"""
        if self.db:
            self.db.close()
            self.db = None
    
    def hash_password(self, password: str) -> str:
        """å“ˆå¸Œå¯†ç """
        return pwd_context.hash(password)
    
    def init_database(self, reset: bool = False):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        print("ğŸš€ å¼€å§‹åˆå§‹åŒ– EdgeAI æ•°æ®åº“...")
        
        if reset:
            print("âš ï¸ é‡ç½®æ•°æ®åº“...")
            drop_tables()
            print("âœ… æ‰€æœ‰è¡¨å·²åˆ é™¤")
        
        # åˆ›å»ºæ‰€æœ‰è¡¨
        create_tables()
        print("âœ… æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")
        
        # åˆ›å»ºåŸºç¡€æ•°æ®
        self._create_basic_data()
        
        print("ğŸ‰ EdgeAI æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
    
    def _create_basic_data(self):
        """åˆ›å»ºåŸºç¡€æ•°æ®"""
        db = self.get_session()
        
        try:
            # åˆ›å»ºç”¨æˆ·
            users = self._create_users(db)
            
            # åˆ›å»ºé¡¹ç›®
            projects = self._create_projects(db, users)
            
            # åˆ›å»ºæ¨¡å‹
            self._create_models(db, users, projects)
            
            # åˆ›å»ºèŠ‚ç‚¹
            self._create_nodes(db, users, projects)
            
            # åˆ›å»ºè¿æ¥å…³ç³»
            self._create_connections(db)
            
            # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
            self._create_metrics(db)
            
            db.commit()
            print("âœ… åŸºç¡€æ•°æ®åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            db.rollback()
            print(f"âŒ åˆ›å»ºåŸºç¡€æ•°æ®å¤±è´¥: {e}")
            raise
        finally:
            self.close_session()
    
    def _create_users(self, db) -> List[User]:
        """åˆ›å»ºç”¨æˆ·æ•°æ®"""
        print("ğŸ‘¤ åˆ›å»ºç”¨æˆ·æ•°æ®...")
        
        users_data = [
            {
                "name": "System Administrator",
                "email": "admin@system.local",
                "password": self.hash_password("admin123")
            },
            {
                "name": "Test User",
                "email": "test@example.com", 
                "password": self.hash_password("test123")
            },
            {
                "name": "EdgeAI Developer",
                "email": "dev@edgeai.com",
                "password": self.hash_password("dev123")
            }
        ]
        
        created_users = []
        for user_data in users_data:
            existing_user = db.query(User).filter(User.email == user_data["email"]).first()
            if not existing_user:
                user = User(**user_data)
                db.add(user)
                db.flush()
                created_users.append(user)
                print(f"  âœ… åˆ›å»ºç”¨æˆ·: {user.name}")
            else:
                created_users.append(existing_user)
                print(f"  âš ï¸ ç”¨æˆ·å·²å­˜åœ¨: {existing_user.name}")
        
        return created_users
    
    def _create_projects(self, db, users: List[User]) -> List[Project]:
        """åˆ›å»ºé¡¹ç›®æ•°æ®"""
        print("ğŸ“ åˆ›å»ºé¡¹ç›®æ•°æ®...")
        
        if not users:
            print("  âŒ æ²¡æœ‰ç”¨æˆ·ï¼Œè·³è¿‡é¡¹ç›®åˆ›å»º")
            return []
        
        admin_user = users[0]
        
        projects_data = [
            {
                "name": "Federated Learning Project",
                "description": "Distributed machine learning with privacy preservation",
                "training_alg": "sft",
                "fed_alg": "fedavg",
                "num_rounds": 10,
                "num_clients": 2,
                "sample_clients": 2,
                "max_steps": 100,
                "lr": "1e-4",
                "dataset_sample": 50,
                "model_name_or_path": "sshleifer/tiny-gpt2",
                "dataset_name": "vicgalle/alpaca-gpt4",
                "status": "completed",
                "progress": 100.0,
                "user_id": admin_user.id
            },
            {
                "name": "MPC Training Project",
                "description": "Multi-party computation for secure training",
                "training_alg": "dpo",
                "fed_alg": "fedprox",
                "num_rounds": 15,
                "num_clients": 3,
                "sample_clients": 2,
                "max_steps": 150,
                "lr": "2e-4",
                "dataset_sample": 100,
                "model_name_or_path": "microsoft/DialoGPT-medium",
                "dataset_name": "wikitext",
                "status": "training",
                "progress": 65.0,
                "user_id": admin_user.id
            },
            {
                "name": "Edge AI Inference",
                "description": "Real-time AI inference on edge devices",
                "training_alg": "ppo",
                "fed_alg": "scaffold",
                "num_rounds": 5,
                "num_clients": 1,
                "sample_clients": 1,
                "max_steps": 50,
                "lr": "5e-4",
                "dataset_sample": 25,
                "model_name_or_path": "gpt2",
                "dataset_name": "squad",
                "status": "pending",
                "progress": 0.0,
                "user_id": admin_user.id
            }
        ]
        
        created_projects = []
        for project_data in projects_data:
            existing_project = db.query(Project).filter(
                Project.name == project_data["name"],
                Project.user_id == project_data["user_id"]
            ).first()
            
            if not existing_project:
                project = Project(**project_data)
                db.add(project)
                db.flush()
                created_projects.append(project)
                print(f"  âœ… åˆ›å»ºé¡¹ç›®: {project.name}")
            else:
                created_projects.append(existing_project)
                print(f"  âš ï¸ é¡¹ç›®å·²å­˜åœ¨: {existing_project.name}")
        
        return created_projects
    
    def _create_models(self, db, users: List[User], projects: List[Project]):
        """åˆ›å»ºæ¨¡å‹æ•°æ®"""
        print("ğŸ¤– åˆ›å»ºæ¨¡å‹æ•°æ®...")
        
        if not users or not projects:
            print("  âŒ ç¼ºå°‘ç”¨æˆ·æˆ–é¡¹ç›®ï¼Œè·³è¿‡æ¨¡å‹åˆ›å»º")
            return
        
        admin_user = users[0]
        main_project = projects[0]
        
        models_data = [
            {
                "name": "ResNet-50 Custom",
                "description": "Custom ResNet-50 model for image classification",
                "file_path": "/models/resnet50_custom.pth",
                "version": "1.0.0",
                "size": 97.8,
                "class_config": {"layers": 50, "classes": 1000, "input_size": [224, 224, 3]},
                "status": "trained",
                "progress": 100.0,
                "loss": 0.15,
                "accuracy": 0.95,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            {
                "name": "BERT Base",
                "description": "BERT base model for sentiment analysis",
                "file_path": "/models/bert_base.bin",
                "version": "1.1.0",
                "size": 440.0,
                "class_config": {"vocab_size": 30522, "hidden_size": 768, "num_layers": 12},
                "status": "training",
                "progress": 65.0,
                "loss": 0.34,
                "accuracy": 0.82,
                "user_id": admin_user.id,
                "project_id": main_project.id
            }
        ]
        
        for model_data in models_data:
            existing_model = db.query(Model).filter(
                Model.name == model_data["name"],
                Model.user_id == model_data["user_id"]
            ).first()
            
            if not existing_model:
                model = Model(**model_data)
                db.add(model)
                print(f"  âœ… åˆ›å»ºæ¨¡å‹: {model.name}")
            else:
                print(f"  âš ï¸ æ¨¡å‹å·²å­˜åœ¨: {existing_model.name}")
    
    def _create_nodes(self, db, users: List[User], projects: List[Project]):
        """åˆ›å»ºèŠ‚ç‚¹æ•°æ®"""
        print("ğŸ”§ åˆ›å»ºèŠ‚ç‚¹æ•°æ®...")
        
        if not users or not projects:
            print("  âŒ ç¼ºå°‘ç”¨æˆ·æˆ–é¡¹ç›®ï¼Œè·³è¿‡èŠ‚ç‚¹åˆ›å»º")
            return
        
        admin_user = users[0]
        main_project = projects[0]
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰èŠ‚ç‚¹æ•°æ®
        existing_nodes = db.query(Node).count()
        if existing_nodes > 0:
            print(f"  âš ï¸ å·²å­˜åœ¨ {existing_nodes} ä¸ªèŠ‚ç‚¹ï¼Œè·³è¿‡åˆ›å»º")
            return
        
        nodes_data = [
            # Model Nodes (æ¨¡å‹èŠ‚ç‚¹)
            {
                "name": "database_model_001_ResNet50_Custom",
                "node_type": "model",
                "role": "Model Server",
                "state": "online",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.100",
                "connected_nodes_count": 5,
                "cpu_usage": 45.2,
                "memory_usage": 67.8,
                "gpu_usage": 82.1,
                "priority": 1,
                "location": "Data Center A",
                "specialty": "Computer Vision",
                "progress": 100.0,
                "cpu": "Intel Xeon E5-2680 v4",
                "gpu": "NVIDIA Tesla V100",
                "memory": "64GB DDR4",
                "hardware_info": '{"cores": 14, "threads": 28, "gpu_memory": "32GB", "storage": "1TB SSD"}',
                "network_latency": 12,
                "uptime": 99.5,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            {
                "name": "database_model_002_VGG16_ImageNet",
                "node_type": "model",
                "role": "Model Server",
                "state": "online",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.101",
                "connected_nodes_count": 5,
                "cpu_usage": 38.7,
                "memory_usage": 52.3,
                "gpu_usage": 75.6,
                "priority": 1,
                "location": "Data Center A",
                "specialty": "Image Classification",
                "progress": 100.0,
                "cpu": "Intel Xeon E5-2680 v4",
                "gpu": "NVIDIA Tesla V100",
                "memory": "64GB DDR4",
                "hardware_info": '{"cores": 14, "threads": 28, "gpu_memory": "32GB", "storage": "1TB SSD"}',
                "network_latency": 15,
                "uptime": 98.8,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            {
                "name": "database_model_003_EfficientNet_B0",
                "node_type": "model",
                "role": "Model Server",
                "state": "training",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.102",
                "connected_nodes_count": 5,
                "cpu_usage": 67.3,
                "memory_usage": 78.9,
                "gpu_usage": 89.2,
                "priority": 1,
                "location": "Data Center A",
                "specialty": "Efficient Networks",
                "progress": 75.0,
                "cpu": "Intel Xeon E5-2680 v4",
                "gpu": "NVIDIA Tesla V100",
                "memory": "64GB DDR4",
                "hardware_info": '{"cores": 14, "threads": 28, "gpu_memory": "32GB", "storage": "1TB SSD"}',
                "network_latency": 18,
                "uptime": 97.2,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            # Control Nodes (æ§åˆ¶èŠ‚ç‚¹)
            {
                "name": "Coordination Center",
                "node_type": "control",
                "role": "Network Coordinator",
                "state": "online",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.200",
                "connected_nodes_count": 5,
                "cpu_usage": 25.1,
                "memory_usage": 34.6,
                "gpu_usage": 0.0,
                "priority": 1,
                "location": "Control Center",
                "specialty": "Network Management",
                "progress": 0.0,
                "cpu": "Intel Xeon E5-2680 v4",
                "gpu": "None",
                "memory": "32GB DDR4",
                "hardware_info": '{"cores": 8, "threads": 16, "storage": "500GB SSD"}',
                "network_latency": 5,
                "uptime": 99.9,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            # Data Nodes (æ•°æ®èŠ‚ç‚¹)
            {
                "name": "database_node_001_GPU_Training",
                "node_type": "data",
                "role": "Training Node",
                "state": "training",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.201",
                "connected_nodes_count": 1,
                "cpu_usage": 80.4,
                "memory_usage": 76.1,
                "gpu_usage": 71.6,
                "priority": 2,
                "location": "Edge Location 1",
                "specialty": "GPU Training",
                "progress": 45.0,
                "cpu": "Intel Core i7-10700K",
                "gpu": "NVIDIA RTX 3080",
                "memory": "32GB DDR4",
                "hardware_info": '{"cores": 8, "threads": 16, "gpu_memory": "10GB", "storage": "1TB NVMe"}',
                "network_latency": 25,
                "uptime": 95.3,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            {
                "name": "database_node_002_GPU_Inference",
                "node_type": "data",
                "role": "Inference Node",
                "state": "inference",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.202",
                "connected_nodes_count": 1,
                "cpu_usage": 0.0,
                "memory_usage": 0.0,
                "gpu_usage": 0.0,
                "priority": 2,
                "location": "Edge Location 2",
                "specialty": "Real-time Inference",
                "progress": 80.0,
                "cpu": "Intel Core i5-10400",
                "gpu": "NVIDIA RTX 3060",
                "memory": "16GB DDR4",
                "hardware_info": '{"cores": 6, "threads": 12, "gpu_memory": "8GB", "storage": "500GB SSD"}',
                "network_latency": 30,
                "uptime": 92.1,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            {
                "name": "database_node_003_Edge_Processing",
                "node_type": "data",
                "role": "Processing Node",
                "state": "processing",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.203",
                "connected_nodes_count": 1,
                "cpu_usage": 0.0,
                "memory_usage": 0.0,
                "gpu_usage": 0.0,
                "priority": 2,
                "location": "Edge Location 3",
                "specialty": "Data Processing",
                "progress": 60.0,
                "cpu": "AMD Ryzen 7 3700X",
                "gpu": "NVIDIA GTX 1660",
                "memory": "16GB DDR4",
                "hardware_info": '{"cores": 8, "threads": 16, "gpu_memory": "6GB", "storage": "500GB SSD"}',
                "network_latency": 35,
                "uptime": 88.7,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            {
                "name": "database_node_004_Data_Processing",
                "node_type": "data",
                "role": "Data Processor",
                "state": "idle",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.204",
                "connected_nodes_count": 1,
                "cpu_usage": 24.1,
                "memory_usage": 34.7,
                "gpu_usage": 0.0,
                "priority": 2,
                "location": "Edge Location 4",
                "specialty": "Data Analysis",
                "progress": 25.0,
                "cpu": "Intel Core i3-10100",
                "gpu": "None",
                "memory": "8GB DDR4",
                "hardware_info": '{"cores": 4, "threads": 8, "storage": "250GB SSD"}',
                "network_latency": 40,
                "uptime": 85.2,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            },
            {
                "name": "database_node_005_Model_Validation",
                "node_type": "data",
                "role": "Validation Node",
                "state": "validation",
                "responsible_user": "System",
                "path_ipv4": "192.168.1.205",
                "connected_nodes_count": 1,
                "cpu_usage": 0.0,
                "memory_usage": 0.0,
                "gpu_usage": 0.0,
                "priority": 2,
                "location": "Edge Location 5",
                "specialty": "Model Validation",
                "progress": 90.0,
                "cpu": "Intel Core i7-9700K",
                "gpu": "NVIDIA RTX 2070",
                "memory": "32GB DDR4",
                "hardware_info": '{"cores": 8, "threads": 8, "gpu_memory": "8GB", "storage": "1TB SSD"}',
                "network_latency": 22,
                "uptime": 91.8,
                "is_active": True,
                "user_id": admin_user.id,
                "project_id": main_project.id
            }
        ]
        
        created_nodes = []
        for node_data in nodes_data:
            node = Node(**node_data)
            db.add(node)
            db.flush()  # è·å–ID
            created_nodes.append(node)
            print(f"  âœ… åˆ›å»ºèŠ‚ç‚¹: {node_data['name']} ({node_data['node_type']})")
        
        return created_nodes
    
    def _create_connections(self, db):
        """åˆ›å»ºèŠ‚ç‚¹è¿æ¥å…³ç³»"""
        print("ğŸ”— åˆ›å»ºèŠ‚ç‚¹è¿æ¥å…³ç³»...")
        
        # è·å–æ‰€æœ‰èŠ‚ç‚¹
        nodes = db.query(Node).all()
        model_nodes = [n for n in nodes if n.node_type == 'model']
        data_nodes = [n for n in nodes if n.node_type == 'data']
        control_nodes = [n for n in nodes if n.node_type == 'control']
        
        # æ¨¡å‹èŠ‚ç‚¹è¿æ¥åˆ°æ‰€æœ‰æ•°æ®èŠ‚ç‚¹
        for model_node in model_nodes:
            for data_node in data_nodes:
                connection = NodeConnection(
                    from_node_id=model_node.id,
                    to_node_id=data_node.id,
                    connection_type='data',
                    strength=1.0,
                    is_active=True
                )
                db.add(connection)
        
        # æ§åˆ¶èŠ‚ç‚¹è¿æ¥åˆ°æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹
        all_other_nodes = [n for n in nodes if n.node_type != 'control']
        for control_node in control_nodes:
            for other_node in all_other_nodes:
                connection = NodeConnection(
                    from_node_id=control_node.id,
                    to_node_id=other_node.id,
                    connection_type='control',
                    strength=0.8,
                    is_active=True
                )
                db.add(connection)
        
        print(f"  âœ… åˆ›å»ºäº† {len(model_nodes) * len(data_nodes) + len(control_nodes) * len(all_other_nodes)} ä¸ªè¿æ¥å…³ç³»")
    
    def _create_metrics(self, db):
        """åˆ›å»ºæ€§èƒ½æŒ‡æ ‡æ•°æ®"""
        print("ğŸ“Š åˆ›å»ºæ€§èƒ½æŒ‡æ ‡æ•°æ®...")
        
        nodes = db.query(Node).all()
        
        for node in nodes:
            # ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ›å»ºè¿‡å»24å°æ—¶çš„å†å²æ•°æ®
            for hours_ago in range(24, 0, -1):
                timestamp = datetime.now() - timedelta(hours=hours_ago)
                
                # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®å˜åŒ–
                base_cpu = node.cpu_usage or 0
                base_memory = node.memory_usage or 0
                base_gpu = node.gpu_usage or 0
                
                # æ·»åŠ ä¸€äº›éšæœºå˜åŒ–
                cpu_variation = random.uniform(-10, 10)
                memory_variation = random.uniform(-5, 5)
                gpu_variation = random.uniform(-15, 15)
                
                metric = NodeMetric(
                    node_id=node.id,
                    timestamp=timestamp,
                    cpu_usage=max(0, min(100, base_cpu + cpu_variation)),
                    memory_usage=max(0, min(100, base_memory + memory_variation)),
                    gpu_usage=max(0, min(100, base_gpu + gpu_variation)),
                    network_usage=random.uniform(10, 50),
                    temperature=random.uniform(35, 75),
                    power_consumption=random.uniform(50, 200),
                    disk_usage=random.uniform(20, 80)
                )
                db.add(metric)
        
        print(f"  âœ… ä¸º {len(nodes)} ä¸ªèŠ‚ç‚¹åˆ›å»ºäº†å†å²æ€§èƒ½æ•°æ®")
    
    def get_database_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        db = self.get_session()
        
        try:
            stats = {
                "users": db.query(User).count(),
                "projects": db.query(Project).count(),
                "models": db.query(Model).count(),
                "nodes": db.query(Node).count(),
                "connections": db.query(NodeConnection).count(),
                "metrics": db.query(NodeMetric).count()
            }
            
            # æŒ‰ç±»å‹ç»Ÿè®¡èŠ‚ç‚¹
            stats["nodes_by_type"] = {
                "model": db.query(Node).filter(Node.node_type == 'model').count(),
                "control": db.query(Node).filter(Node.node_type == 'control').count(),
                "data": db.query(Node).filter(Node.node_type == 'data').count()
            }
            
            return stats
            
        finally:
            self.close_session()
    
    def test_database(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“åŠŸèƒ½"""
        print("ğŸ§ª æµ‹è¯•æ•°æ®åº“åŠŸèƒ½...")
        
        try:
            # æµ‹è¯•è¿æ¥
            db = self.get_session()
            
            # æµ‹è¯•æŸ¥è¯¢
            user_count = db.query(User).count()
            project_count = db.query(Project).count()
            node_count = db.query(Node).count()
            
            print(f"  âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
            print(f"  âœ… ç”¨æˆ·æ•°é‡: {user_count}")
            print(f"  âœ… é¡¹ç›®æ•°é‡: {project_count}")
            print(f"  âœ… èŠ‚ç‚¹æ•°é‡: {node_count}")
            
            # æµ‹è¯•æ–°å­—æ®µ
            project = db.query(Project).first()
            if project:
                new_fields = [
                    'training_alg', 'fed_alg', 'num_rounds', 'num_clients',
                    'sample_clients', 'max_steps', 'lr', 'dataset_sample',
                    'model_name_or_path', 'dataset_name'
                ]
                
                for field in new_fields:
                    value = getattr(project, field, None)
                    if value is not None:
                        print(f"  âœ… å­—æ®µ {field}: {value}")
                    else:
                        print(f"  âŒ å­—æ®µ {field} ä¸å­˜åœ¨")
            
            self.close_session()
            return True
            
        except Exception as e:
            print(f"  âŒ æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def reset_database(self):
        """é‡ç½®æ•°æ®åº“"""
        print("âš ï¸ é‡ç½®æ•°æ®åº“...")
        self.init_database(reset=True)
    
    def cleanup_old_files(self):
        """æ¸…ç†æ—§çš„æ•°æ®åº“æ–‡ä»¶"""
        print("ğŸ§¹ æ¸…ç†æ—§çš„æ•°æ®åº“æ–‡ä»¶...")
        
        old_files = [
            "init_db.py",
            "init_test_data.py", 
            "init_nodes_data.py",
            "seed_node_data.py",
            "test_new_fields.py",
            "migrate_enhanced_nodes.py",
            "migrate_add_training_fields.py"
        ]
        
        for filename in old_files:
            filepath = Path(__file__).parent / filename
            if filepath.exists():
                filepath.unlink()
                print(f"  âœ… åˆ é™¤æ–‡ä»¶: {filename}")
        
        print("  âœ… æ—§æ–‡ä»¶æ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="EdgeAI ç»Ÿä¸€æ•°æ®åº“ç®¡ç†å™¨")
    parser.add_argument("--init", action="store_true", help="åˆå§‹åŒ–æ•°æ®åº“")
    parser.add_argument("--reset", action="store_true", help="é‡ç½®æ•°æ®åº“")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•æ•°æ®åº“")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡")
    parser.add_argument("--cleanup", action="store_true", help="æ¸…ç†æ—§æ–‡ä»¶")
    
    args = parser.parse_args()
    
    manager = EdgeAIDatabaseManager()
    
    try:
        if args.reset:
            manager.reset_database()
        elif args.init:
            manager.init_database()
        elif args.test:
            success = manager.test_database()
            sys.exit(0 if success else 1)
        elif args.stats:
            stats = manager.get_database_stats()
            print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
            print(f"  ğŸ‘¥ ç”¨æˆ·æ•°é‡: {stats['users']}")
            print(f"  ğŸ“ é¡¹ç›®æ•°é‡: {stats['projects']}")
            print(f"  ğŸ¤– æ¨¡å‹æ•°é‡: {stats['models']}")
            print(f"  ğŸ”§ èŠ‚ç‚¹æ•°é‡: {stats['nodes']}")
            print(f"  ğŸ”— è¿æ¥å…³ç³»: {stats['connections']}")
            print(f"  ğŸ“Š æ€§èƒ½æŒ‡æ ‡: {stats['metrics']}")
            print(f"\nğŸ”§ èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ:")
            for node_type, count in stats['nodes_by_type'].items():
                print(f"  - {node_type}: {count}")
        elif args.cleanup:
            manager.cleanup_old_files()
        else:
            # é»˜è®¤è¡Œä¸ºï¼šåˆå§‹åŒ–æ•°æ®åº“
            manager.init_database()
            
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        manager.close_session()


if __name__ == "__main__":
    main()
