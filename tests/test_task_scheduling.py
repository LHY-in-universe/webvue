#!/usr/bin/env python3
"""
ä»»åŠ¡è°ƒåº¦å’Œå¹¶å‘æ§åˆ¶åŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯ä»»åŠ¡é˜Ÿåˆ—ã€è°ƒåº¦å™¨å’Œå¹¶å‘æ§åˆ¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import sys
import os
import json
import time
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'database'))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('task_scheduling_test.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class TaskSchedulingTester:
    """ä»»åŠ¡è°ƒåº¦åŠŸèƒ½æµ‹è¯•å™¨"""

    def __init__(self):
        self.test_results = {}
        self.start_time = time.time()

    async def run_all_tests(self) -> bool:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ Starting Task Scheduling Tests")
        logger.info("=" * 60)

        tests = [
            ("Database Models", self.test_database_models),
            ("Task Scheduler Config", self.test_scheduler_config),
            ("Task Monitor", self.test_task_monitor),
            ("Task Queue Operations", self.test_task_queue_operations),
            ("Concurrency Control", self.test_concurrency_control),
            ("Priority Ordering", self.test_priority_ordering),
            ("Error Handling", self.test_error_handling),
            ("API Endpoints", self.test_api_endpoints),
        ]

        passed = 0
        total = len(tests)

        for test_name, test_func in tests:
            logger.info(f"\n{'='*20} {test_name} {'='*20}")
            try:
                result = await test_func()
                self.test_results[test_name] = result
                if result:
                    logger.info(f"âœ… {test_name} - PASSED")
                    passed += 1
                else:
                    logger.error(f"âŒ {test_name} - FAILED")
            except Exception as e:
                logger.error(f"âŒ {test_name} - ERROR: {e}")
                self.test_results[test_name] = False

        # æµ‹è¯•æ‘˜è¦
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ¯ TEST SUMMARY")
        logger.info("=" * 60)

        for test_name, result in self.test_results.items():
            status = "âœ… PASSED" if result else "âŒ FAILED"
            logger.info(f"{test_name:<30} {status}")

        elapsed_time = time.time() - self.start_time
        logger.info(f"\nResults: {passed}/{total} tests passed")
        logger.info(f"Elapsed time: {elapsed_time:.2f} seconds")

        if passed == total:
            logger.info("ğŸ‰ All tests passed! Task scheduling system is working correctly.")
            return True
        else:
            logger.warning("âš ï¸ Some tests failed. Please review the issues above.")
            return False

    async def test_database_models(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“æ¨¡å‹"""
        try:
            from database.edgeai.models import TaskQueue, Project

            logger.info("Testing TaskQueue model structure...")

            # æ£€æŸ¥ TaskQueue æ¨¡å‹å±æ€§
            expected_fields = [
                'id', 'project_id', 'status', 'priority', 'task_config',
                'created_at', 'started_at', 'completed_at',
                'retry_count', 'max_retries', 'error_message', 'external_task_id'
            ]

            for field in expected_fields:
                if not hasattr(TaskQueue, field):
                    logger.error(f"TaskQueue model missing field: {field}")
                    return False

            logger.info("âœ… TaskQueue model structure is correct")

            # æ£€æŸ¥ç´¢å¼•å®šä¹‰
            table = TaskQueue.__table__
            index_names = [idx.name for idx in table.indexes if idx.name]
            logger.info(f"TaskQueue indexes: {index_names}")

            expected_indexes = ['idx_queue_order', 'idx_project_queue']
            for idx_name in expected_indexes:
                if idx_name not in index_names:
                    logger.warning(f"Expected index {idx_name} not found (may be created by migration)")

            return True

        except ImportError as e:
            logger.error(f"Failed to import models: {e}")
            return False
        except Exception as e:
            logger.error(f"Database model test failed: {e}")
            return False

    async def test_scheduler_config(self) -> bool:
        """æµ‹è¯•è°ƒåº¦å™¨é…ç½®"""
        try:
            from backend.edgeai.config.scheduler_config import SchedulerConfig, get_config

            logger.info("Testing scheduler configuration...")

            # æµ‹è¯•é»˜è®¤é…ç½®
            config = SchedulerConfig()
            logger.info(f"Default MAX_CONCURRENT_TASKS: {config.MAX_CONCURRENT_TASKS}")
            logger.info(f"Default QUEUE_CHECK_INTERVAL: {config.QUEUE_CHECK_INTERVAL}")

            # æµ‹è¯•é…ç½®éªŒè¯
            config.MAX_CONCURRENT_TASKS = 2
            config.TASK_TIMEOUT = 1800
            config.validate()
            logger.info("âœ… Configuration validation works")

            # æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®
            os.environ['SCHEDULER_MAX_CONCURRENT_TASKS'] = '2'
            env_config = SchedulerConfig.from_env()
            if env_config.MAX_CONCURRENT_TASKS == 2:
                logger.info("âœ… Environment variable configuration works")
            else:
                logger.error("âŒ Environment variable configuration failed")
                return False

            # æ¸…ç†ç¯å¢ƒå˜é‡
            if 'SCHEDULER_MAX_CONCURRENT_TASKS' in os.environ:
                del os.environ['SCHEDULER_MAX_CONCURRENT_TASKS']

            return True

        except Exception as e:
            logger.error(f"Scheduler config test failed: {e}")
            return False

    async def test_task_monitor(self) -> bool:
        """æµ‹è¯•ä»»åŠ¡ç›‘æ§"""
        try:
            from backend.edgeai.monitoring.task_monitor import TaskMonitor, TaskMetrics

            logger.info("Testing task monitor...")

            monitor = TaskMonitor()
            logger.info("âœ… TaskMonitor created successfully")

            # æµ‹è¯•æŒ‡æ ‡æ•°æ®ç»“æ„
            metrics = TaskMetrics()
            metrics.total_tasks = 10
            metrics.success_rate = 85.5

            metrics_dict = metrics.to_dict()
            if 'total_tasks' in metrics_dict and 'success_rate' in metrics_dict:
                logger.info("âœ… TaskMetrics serialization works")
            else:
                logger.error("âŒ TaskMetrics serialization failed")
                return False

            # æµ‹è¯•äº‹ä»¶è®°å½•
            monitor.record_task_event('test_event', 123, test_data='test_value')
            events = monitor.get_recent_events(limit=1)
            if len(events) > 0 and events[0]['type'] == 'task_event':
                logger.info("âœ… Event recording works")
            else:
                logger.error("âŒ Event recording failed")
                return False

            return True

        except Exception as e:
            logger.error(f"Task monitor test failed: {e}")
            return False

    async def test_task_queue_operations(self) -> bool:
        """æµ‹è¯•ä»»åŠ¡é˜Ÿåˆ—æ“ä½œ"""
        try:
            from backend.edgeai.scheduler.task_scheduler import TaskScheduler
            from database.edgeai.database import SessionLocal

            logger.info("Testing task queue operations...")

            # åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
            scheduler = TaskScheduler()
            logger.info("âœ… TaskScheduler created successfully")

            # æµ‹è¯•é˜Ÿåˆ—çŠ¶æ€æ£€æŸ¥
            db = SessionLocal()
            try:
                status = scheduler.get_queue_status(db)
                logger.info(f"Queue status: {status['scheduler_status']}")
                logger.info(f"Queue stats: {status['queue_stats']}")
                logger.info("âœ… Queue status retrieval works")
            finally:
                db.close()

            # æµ‹è¯•å¹¶å‘é™åˆ¶æ£€æŸ¥
            can_start = scheduler.can_start_new_task()
            logger.info(f"Can start new task: {can_start}")
            logger.info("âœ… Concurrency check works")

            return True

        except Exception as e:
            logger.error(f"Task queue operations test failed: {e}")
            return False

    async def test_concurrency_control(self) -> bool:
        """æµ‹è¯•å¹¶å‘æ§åˆ¶"""
        logger.info("Testing concurrency control...")

        try:
            from backend.edgeai.scheduler.task_scheduler import TaskScheduler

            scheduler = TaskScheduler()

            # æ¨¡æ‹Ÿæ·»åŠ å¤šä¸ªè¿è¡Œä¸­çš„ä»»åŠ¡æ¥æµ‹è¯•å¹¶å‘é™åˆ¶
            scheduler.running_tasks['task1'] = {
                'queue_task_id': 1,
                'project_id': 1,
                'started_at': datetime.utcnow()
            }

            # ç°åœ¨åº”è¯¥ä¸èƒ½å¯åŠ¨æ–°ä»»åŠ¡ (å› ä¸ºé»˜è®¤å¹¶å‘é™åˆ¶æ˜¯1)
            can_start = scheduler.can_start_new_task()
            if not can_start:
                logger.info("âœ… Concurrency limit enforced correctly")
            else:
                logger.error("âŒ Concurrency limit not working")
                return False

            # æ¸…ç†æµ‹è¯•æ•°æ®
            scheduler.running_tasks.clear()

            # ç°åœ¨åº”è¯¥å¯ä»¥å¯åŠ¨ä»»åŠ¡äº†
            can_start = scheduler.can_start_new_task()
            if can_start:
                logger.info("âœ… Concurrency control allows tasks when under limit")
            else:
                logger.error("âŒ Concurrency control blocking when it shouldn't")
                return False

            return True

        except Exception as e:
            logger.error(f"Concurrency control test failed: {e}")
            return False

    async def test_priority_ordering(self) -> bool:
        """æµ‹è¯•ä¼˜å…ˆçº§æ’åº"""
        logger.info("Testing priority ordering...")

        # è¿™ä¸ªæµ‹è¯•éœ€è¦å®é™…çš„æ•°æ®åº“è¿æ¥ï¼Œè¿™é‡Œåšä¸€ä¸ªç®€åŒ–çš„é€»è¾‘æµ‹è¯•
        try:
            # æ¨¡æ‹Ÿä¼˜å…ˆçº§æ’åºé€»è¾‘
            tasks = [
                {'priority': 5, 'created_at': '2023-01-01 10:00:00'},
                {'priority': 1, 'created_at': '2023-01-01 11:00:00'},  # é«˜ä¼˜å…ˆçº§
                {'priority': 5, 'created_at': '2023-01-01 09:00:00'},  # åŒä¼˜å…ˆçº§ä½†æ›´æ—©
            ]

            # æŒ‰ä¼˜å…ˆçº§ ASC, åˆ›å»ºæ—¶é—´ ASC æ’åº
            sorted_tasks = sorted(tasks, key=lambda x: (x['priority'], x['created_at']))

            # éªŒè¯æ’åºç»“æœ
            if (sorted_tasks[0]['priority'] == 1 and
                sorted_tasks[1]['created_at'] == '2023-01-01 09:00:00' and
                sorted_tasks[2]['created_at'] == '2023-01-01 10:00:00'):
                logger.info("âœ… Priority ordering logic correct")
                return True
            else:
                logger.error("âŒ Priority ordering logic incorrect")
                return False

        except Exception as e:
            logger.error(f"Priority ordering test failed: {e}")
            return False

    async def test_error_handling(self) -> bool:
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        logger.info("Testing error handling...")

        try:
            from backend.edgeai.scheduler.task_scheduler import TaskScheduler

            scheduler = TaskScheduler()

            # æµ‹è¯•æ— æ•ˆé¡¹ç›®ID
            try:
                scheduler.add_task_to_queue(project_id=999999, priority=5)
                logger.error("âŒ Should have raised error for invalid project ID")
                return False
            except Exception as e:
                logger.info(f"âœ… Correctly handled invalid project ID: {type(e).__name__}")

            # æµ‹è¯•æ— æ•ˆä¼˜å…ˆçº§
            try:
                scheduler.add_task_to_queue(project_id=1, priority=15)  # è¶…å‡ºæœ‰æ•ˆèŒƒå›´
                # æ³¨æ„ï¼šè¿™ä¸ªæµ‹è¯•å–å†³äºæ˜¯å¦åœ¨ add_task_to_queue ä¸­å®ç°äº†ä¼˜å…ˆçº§éªŒè¯
                logger.info("Priority validation might not be implemented in add_task_to_queue")
            except Exception as e:
                logger.info(f"Priority validation: {type(e).__name__}")

            return True

        except Exception as e:
            logger.error(f"Error handling test failed: {e}")
            return False

    async def test_api_endpoints(self) -> bool:
        """æµ‹è¯•APIç«¯ç‚¹ (æ¨¡æ‹Ÿæµ‹è¯•)"""
        logger.info("Testing API endpoints (simulated)...")

        try:
            # ç”±äºæˆ‘ä»¬æ²¡æœ‰è¿è¡Œçš„æœåŠ¡å™¨ï¼Œè¿™é‡Œè¿›è¡Œé€»è¾‘éªŒè¯
            # æ£€æŸ¥ API å‡½æ•°æ˜¯å¦å¯ä»¥å¯¼å…¥
            from backend.edgeai.api.training import (
                get_queue_status,
                cancel_queued_task,
                get_project_queue_status,
                start_scheduler,
                stop_scheduler
            )

            logger.info("âœ… API functions imported successfully")

            # æ£€æŸ¥ API å‡½æ•°ç­¾å
            import inspect

            # get_queue_status åº”è¯¥æ¥å— db å‚æ•°
            sig = inspect.signature(get_queue_status)
            if 'db' in sig.parameters:
                logger.info("âœ… get_queue_status has correct signature")
            else:
                logger.error("âŒ get_queue_status missing db parameter")
                return False

            # cancel_queued_task åº”è¯¥æ¥å— queue_task_id å’Œ db å‚æ•°
            sig = inspect.signature(cancel_queued_task)
            expected_params = {'queue_task_id', 'db'}
            actual_params = set(sig.parameters.keys())
            if expected_params.issubset(actual_params):
                logger.info("âœ… cancel_queued_task has correct signature")
            else:
                logger.error(f"âŒ cancel_queued_task missing parameters: {expected_params - actual_params}")
                return False

            return True

        except ImportError as e:
            logger.error(f"Failed to import API functions: {e}")
            return False
        except Exception as e:
            logger.error(f"API endpoints test failed: {e}")
            return False

    def generate_test_report(self) -> Dict:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = {
            'test_run_time': datetime.utcnow().isoformat(),
            'total_duration': time.time() - self.start_time,
            'results': self.test_results,
            'summary': {
                'total_tests': len(self.test_results),
                'passed': sum(1 for r in self.test_results.values() if r),
                'failed': sum(1 for r in self.test_results.values() if not r),
                'success_rate': (sum(1 for r in self.test_results.values() if r) / len(self.test_results)) * 100
            }
        }

        return report

    def save_report(self, filename: str = 'test_report.json'):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        report = self.generate_test_report()
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"Test report saved to {filename}")


async def main():
    """ä¸»å‡½æ•°"""
    tester = TaskSchedulingTester()

    try:
        success = await tester.run_all_tests()
        tester.save_report()
        return 0 if success else 1

    except KeyboardInterrupt:
        logger.info("Test interrupted by user")
        return 1
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)