from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.trustedhost import TrustedHostMiddleware
import uvicorn
import os
import sys
from pathlib import Path

# Add the root directory to Python path for database imports
root_dir = Path(__file__).parent.parent
sys.path.append(str(root_dir))

# Add the backend directory to Python path for router imports
backend_dir = Path(__file__).parent
sys.path.append(str(backend_dir))

# Import routers
from common.api import router as common_router
from p2pai.api import router as p2pai_router
from edgeai.api import router as edgeai_router

# Import database initialization
from database.edgeai.database import create_tables, get_database_info
from database.edgeai.init_db import init_database

# Import background tasks
from edgeai.background_tasks import start_background_tasks, stop_background_tasks

# Create FastAPI app
app = FastAPI(
    title="OpenTMP LLM Engine API",
    description="Secure and Efficient Distributed Machine Learning Solutions",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    redirect_slashes=True  # å…è®¸é‡å®šå‘æ–œæ 
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173", "http://localhost:5174", "http://localhost:5175", "http://localhost:5176", "http://localhost:5177", "http://localhost:5178", "http://localhost:8000", "http://127.0.0.1:3000", "http://127.0.0.1:5173", "http://127.0.0.1:5174", "http://127.0.0.1:5175", "http://127.0.0.1:5176", "http://127.0.0.1:5177", "http://127.0.0.1:5178", "http://127.0.0.1:8000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Trusted host middleware
app.add_middleware(
    TrustedHostMiddleware, 
    allowed_hosts=["localhost", "127.0.0.1", "0.0.0.0"]
)

# Include routers
app.include_router(common_router, prefix="/api/common", tags=["Common"])
app.include_router(p2pai_router, prefix="/api/p2pai", tags=["P2P AI"])
app.include_router(edgeai_router, prefix="/api/edgeai", tags=["Edge AI"])

@app.get("/")
async def root():
    return {
        "message": "OpenTMP LLM Engine API",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“å’Œåå°ä»»åŠ¡"""
    try:
        print("ğŸš€ Starting OpenTMP LLM Engine API...")

        # è·å–æ•°æ®åº“ä¿¡æ¯
        db_info = get_database_info()
        print(f"ğŸ“Š Database URL: {db_info['database_url']}")

        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        db_path = db_info['database_url'].replace('sqlite:///', '')
        if os.path.exists(db_path):
            print("âœ… Database file already exists")
        else:
            print("ğŸ”„ Initializing database...")
            # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆåˆ›å»ºè¡¨å’Œç¤ºä¾‹æ•°æ®ï¼‰
            init_database()
            print("âœ… Database initialized successfully")

        # å¯åŠ¨åå°ä»»åŠ¡ï¼ˆæ¯60ç§’åŒæ­¥ä¸€æ¬¡è¿œç¨‹çŠ¶æ€ï¼‰
        print("ğŸ”„ Starting background tasks...")
        await start_background_tasks(sync_interval=60)
        print("âœ… Background tasks started")

        print("ğŸ‰ Application startup completed!")

    except Exception as e:
        print(f"âŒ Failed to initialize: {e}")
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©åº”ç”¨ç»§ç»­å¯åŠ¨
        print("âš ï¸  Application will continue with limited functionality")


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶åœæ­¢åå°ä»»åŠ¡"""
    try:
        print("ğŸ›‘ Stopping background tasks...")
        await stop_background_tasks()
        print("âœ… Background tasks stopped")
        print("ğŸ‘‹ Application shutdown completed")

    except Exception as e:
        print(f"âŒ Error during shutdown: {e}")

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )